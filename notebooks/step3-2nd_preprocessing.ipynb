{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3-2nd preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Impot necessary modules & start a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName('ADS_project_1.py')\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True)\n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .config('spark.sql.session.timeZone', 'Etc/UTC')\n",
    "    .config('spark.driver.memory', '16g')\n",
    "    .config('spark.executer.memory', '16g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data import & overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import raw `TLC_data` from directory `data/raw/TLC_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data_path = '../data/raw/TLC_data/TLC_data.parquet/'\n",
    "TLC_data = spark.read.parquet(TLC_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show #rows, #cols & overview of `TLC_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_after_1st_preprocessing = TLC_data.count()\n",
    "num_cols_after_1st_preprocessing = len(TLC_data.columns)\n",
    "\n",
    "print('number of rows: ', num_rows_after_1st_preprocessing)\n",
    "print('number of cols: ', num_cols_after_1st_preprocessing)\n",
    "TLC_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove features with invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the summary statistics of the entire dataset\n",
    "TLC_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice there exists invalid values in the features '#passenger', 'trip_distance' and 'extra_fee', then remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = TLC_data.where(F.col('#passenger') > 0) \\\n",
    "                   .where(F.col('trip_distance') > 0) \\\n",
    "                   .where(F.col('extra_fee') > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that all the values in the feature 'airport_fee' are `null`, then remove the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = TLC_data.drop('airport_fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice there exists a lot of `null` in the feature 'congestion_fee', then change them to `0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = TLC_data.fillna({\"congestion_fee\": 0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of rows: ', TLC_data.count())\n",
    "print('number of cols: ', len(TLC_data.columns))\n",
    "TLC_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features for further analysis: 'date', 'trip_duration', 'average_speed', 'if_weekend', 'if_peak_hour', 'if_overnight', 'if_airport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = (\n",
    "    TLC_data\n",
    "        # Create 'date' from 'pickup_time' by extracting month and day\n",
    "        .withColumn('date', F.date_format('pickup_time', 'MM-dd'))\n",
    "\n",
    "        # Create 'trip_duration' from 'dropoff_time' & 'pickup_time', in unit (s)\n",
    "        .withColumn('trip_duration', F.unix_timestamp('dropoff_time') - F.unix_timestamp('pickup_time'))\n",
    "\n",
    "        # Create 'average_speed' from 'trip_distance' & 'trip_duration', in unit (miles/h)\n",
    "        .withColumn('average_speed', F.col('trip_distance') / (F.col('trip_duration') / 3600))\n",
    "        .withColumn('average_speed', F.col('average_speed').cast('float'))\n",
    "        .withColumn('average_speed', F.round(F.col('average_speed'), 2))\n",
    "\n",
    "        # Create 'if_weekend' from 'pickup_time', values are 0 & 1\n",
    "        .withColumn('if_weekend', F.dayofweek('pickup_time').isin([1, 7]).cast(IntegerType()))\n",
    "\n",
    "        # Create 'if_morning_peak' from 'pickup_time', values are 0 & 1\n",
    "        .withColumn('if_morning_peak', (F.hour('pickup_time').between(7, 10)).cast(IntegerType()))\n",
    "\n",
    "        # Create 'if_evening_peak' from 'pickup_time', values are 0 & 1\n",
    "        .withColumn('if_evening_peak', (F.hour('pickup_time').between(16, 19)).cast(IntegerType()))\n",
    "\n",
    "        # Create 'if_peak_hour' from 'if_morning_peak' & 'if_evening_peak', values are 0 & 1\n",
    "        .withColumn('if_peak_hour', F.expr(\"if_morning_peak = 1 OR if_evening_peak = 1\").cast(IntegerType()))\n",
    "\n",
    "        # Create 'if_overnight' from 'pickup_time', values are 0 & 1\n",
    "        .withColumn('if_overnight', (F.hour('pickup_time').isin([23, 0, 1, 2, 3, 4, 5, 6]).cast(IntegerType())))\n",
    "\n",
    "        # Create 'if_airport' from 'up_location_id' & 'off_location_id', values are 0 & 1\n",
    "        .withColumn(\n",
    "            'if_airport',\n",
    "            ((F.col('up_location_id')).isin([1, 132, 138]) | (F.col('off_location_id')).isin([1, 132, 138]))\n",
    "            .cast(IntegerType())\n",
    "        )\n",
    ")\n",
    "\n",
    "TLC_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of rows: ', TLC_data.count())\n",
    "print('number of cols: ', len(TLC_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Remove invalid values in the new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics of 2 new features, which may exists invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data.describe('trip_duration', 'average_speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice there exists invalid values in the features 'trip_duration' & 'average_speed', then remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = TLC_data.where(F.col('trip_duration') > 0) \\\n",
    "                   .where(F.col('average_speed') > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Changes for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete features that have already been used to extract information and no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_feature_list = ['pickup_time', 'dropoff_time', 'extra_fee', 'if_morning_peak', 'if_evening_peak']\n",
    "\n",
    "for used_feature in used_feature_list:\n",
    "    TLC_data = TLC_data.drop(used_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the features for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLC_data = TLC_data.select(\n",
    "    'date', 'up_location_id', 'off_location_id', '#passenger', 'trip_distance', 'trip_duration', 'average_speed', \n",
    "    'congestion_fee', 'toll_fee', 'if_weekend', 'if_peak_hour', 'if_overnight', 'if_airport'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data shape after creating new features and removing some invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of rows: ', TLC_data.count())\n",
    "print('number of cols: ', len(TLC_data.columns))\n",
    "TLC_data.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 sample `TLC_data` for box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample size and sample from TLC_data\n",
    "sample_size = 0.01\n",
    "sample_TLC_data = TLC_data.sample(sample_size, seed=1).toPandas()\n",
    "print('#rows_of_sample_data: ', len(sample_TLC_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Plot a box plot to detect outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of features, which may exists outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_feature_list = ['trip_distance', 'trip_duration', 'average_speed', 'congestion_fee', 'toll_fee']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the box plot for detecting outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for the features in the list\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,5))\n",
    "for i in range(0, 5):\n",
    "    axs[i].boxplot(sample_TLC_data[figure_feature_list[i]])\n",
    "    axs[i].set_xlabel(figure_feature_list[i], size = 16)\n",
    "fig.suptitle(f\"Boxplot\", fontsize=18)\n",
    "\n",
    "plt.savefig('../plots/boxplot_for_detecting_outlier_1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congestion_fee并没有outlier，所以不进行移除outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there's no oulier in the feature 'congestion_fee', so we decide not to remove outliers for this feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we did remove outliers for 'toll_fee' as well, but after replotting the box plot we find that all values except 0 are removed. We thought the definition of outliers is too strict for this feature, so we decided not to remove outliers for 'toll_fee'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Remove outliers using IQR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine the features which outliers should be removed from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_feature_list = ['trip_distance', 'trip_duration', 'average_speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each feature in figure_feature_list and remove outliers\n",
    "for feature in figure_feature_list:\n",
    "    quantiles = TLC_data.approxQuantile(feature, [0.25, 0.75], 0.05)\n",
    "    Q1 = quantiles[0]\n",
    "    Q3 = quantiles[1]\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    TLC_data = TLC_data.filter((F.col(feature) >= lower_bound) & (F.col(feature) <= upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Replot the box plot after removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新取样并绘制移除完outlier之后的箱形图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample from `TLC_data` and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample with sample_size = 0.01\n",
    "sample_size = 0.01\n",
    "sample_TLC_data = TLC_data.sample(sample_size, seed=1).toPandas()\n",
    "\n",
    "# Replot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "for i in range(0, 3):\n",
    "    axs[i].boxplot(sample_TLC_data[figure_feature_list[i]])\n",
    "    axs[i].set_xlabel(figure_feature_list[i], size = 16)\n",
    "fig.suptitle(f\"Boxplot\", fontsize=18)\n",
    "\n",
    "plt.savefig('../plots/boxplot_for_detecting_outlier_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot looks much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data overview after 2nd preprocessing & saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TLC_data` overview after 2nd preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_after_2nd_preprocessing = TLC_data.count()\n",
    "num_cols_after_2nd_preprocessing = len(TLC_data.columns)\n",
    "\n",
    "num_removed_rows = num_rows_after_1st_preprocessing - num_rows_after_2nd_preprocessing\n",
    "\n",
    "print('number of rows: ', num_rows_after_2nd_preprocessing)\n",
    "print('number of cols: ', num_cols_after_2nd_preprocessing)\n",
    "print('\\n')\n",
    "print('number of removed rows: ', num_removed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `TLC_data` to directory `data/curated/TLC_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory for saving 2nd preprocessed data\n",
    "directory = ('../data/curated/TLC_data')\n",
    "# Check if the directory exists; if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save TLC_data\n",
    "TLC_data.write.mode('overwrite').parquet('../data/curated/TLC_data/TLC_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stop spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
