{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step8-model & analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Impot necessary modules & start a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName('step_1-download_data.py')\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True)\n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .config('spark.sql.session.timeZone', 'Etc/UTC')\n",
    "    .config('spark.driver.memory', '16g')\n",
    "    .config('spark.executer.memory', '16g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation before models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import `merged_data` & `merged_data_for_test` from the directory `data/merged_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_path = '../data/merged_data/merged_data.parquet/'\n",
    "merged_data = spark.read.parquet(merged_data_path)\n",
    "\n",
    "merged_data_for_test_path = '../data/merged_data/merged_data_for_test.parquet/'\n",
    "merged_data_for_test = spark.read.parquet(merged_data_for_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create `train_data` & `test_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `train_data` by sampling from `merged_data`, with sample_size = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 0.004\n",
    "train_data = merged_data.sample(sample_size, seed=1).toPandas()\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `test_data` by sampling from `merged_data_for_test`, with sample_size = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 0.01\n",
    "test_data = merged_data_for_test.sample(sample_size, seed=1).toPandas()\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Change the continuous features of type `int` or `object` to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['trip_duration'] = train_data['trip_duration'].astype(float)\n",
    "train_data['uv_index'] = train_data['uv_index'].astype(float)\n",
    "train_data['temperature'] = pd.to_numeric(train_data['temperature'], errors='coerce')\n",
    "train_data['visibility'] = pd.to_numeric(train_data['visibility'], errors='coerce')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['trip_duration'] = test_data['trip_duration'].astype(float)\n",
    "test_data['uv_index'] = test_data['uv_index'].astype(float)\n",
    "test_data['temperature'] = pd.to_numeric(test_data['temperature'], errors='coerce')\n",
    "test_data['visibility'] = pd.to_numeric(test_data['visibility'], errors='coerce')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Remove the features which will not be used in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['date', 'average_speed', 'visibility'])\n",
    "test_data = test_data.drop(columns=['date', 'average_speed', 'visibility'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Show data shapes of `train_data` & `test_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#rows of train_data: ', len(train_data))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#rows of test_data: ', len(test_data))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2 feature lists\n",
    "continuous_features = ['#passenger', 'trip_distance', 'congestion_fee', 'toll_fee', 'temperature', 'uv_index']\n",
    "discrete_features = [\n",
    "    'up_location_id', 'off_location_id', 'if_weekend', 'if_peak_hour', 'if_overnight', \n",
    "    'if_airport', 'if_rain', 'if_snow', 'if_overcast', 'if_cloudy', 'if_clear'\n",
    "]\n",
    "\n",
    "# Create the interaction term for 'up_location_id' & 'off_location_id'\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "interaction_term_train = interaction.fit_transform(train_data[['up_location_id', 'off_location_id']])\n",
    "interaction_term_test = interaction.transform(test_data[['up_location_id', 'off_location_id']])\n",
    "\n",
    "# Add the interaction term to train_data & test_data\n",
    "train_data['location_interaction_term'] = interaction_term_train[:, 2]\n",
    "test_data['location_interaction_term'] = interaction_term_test[:, 2]\n",
    "\n",
    "# Add 'location_interaction_term' to discrete_features\n",
    "discrete_features.append('location_interaction_term')\n",
    "\n",
    "# Process continuous and discrete features at the same time\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', 'passthrough', discrete_features)  \n",
    "    ])\n",
    "\n",
    "# Split train_data to train_data_X & train_data_Y\n",
    "train_data_X = train_data.drop('trip_duration', axis=1)\n",
    "train_data_Y = train_data['trip_duration']\n",
    "\n",
    "# Split test_data to test_data_X & test_data_Y\n",
    "test_data_X = test_data.drop('trip_duration', axis=1)\n",
    "test_data_Y = test_data['trip_duration']\n",
    "\n",
    "# Create & train linear regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearRegression())\n",
    "])\n",
    "\n",
    "model.fit(train_data_X, train_data_Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Use linear regression model to predict & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict test_data\n",
    "train_prediction_Y = model.predict(train_data_X)\n",
    "test_prediction_Y = model.predict(test_data_X)\n",
    "\n",
    "# Calculate R^2 & MSE for train result\n",
    "train_r2 = r2_score(train_data_Y, train_prediction_Y)\n",
    "train_mse = mean_squared_error(train_data_Y, train_prediction_Y)\n",
    "\n",
    "# Calculate R^2 & MSE for test result\n",
    "test_r2 = r2_score(test_data_Y, test_prediction_Y)\n",
    "test_mse = mean_squared_error(test_data_Y, test_prediction_Y)\n",
    "\n",
    "# Show the results\n",
    "print(f\"Train R^2: {train_r2:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print('\\n')\n",
    "print(f\"Test R^2: {test_r2:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random forest regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Build random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction term by combining 'up_location_id' & 'off_location_id'\n",
    "train_data_X['location_interaction_term'] = train_data_X['up_location_id'].astype(str) + '_' + train_data_X['off_location_id'].astype(str)\n",
    "test_data_X['location_interaction_term'] = test_data_X['up_location_id'].astype(str) + '_' + test_data_X['off_location_id'].astype(str)\n",
    "\n",
    "# Define 2 feature lists\n",
    "continuous_features = ['#passenger', 'trip_distance', 'congestion_fee', 'toll_fee', 'temperature', 'uv_index']\n",
    "discrete_features = [\n",
    "    'up_location_id', 'off_location_id', 'if_weekend', 'if_peak_hour', 'if_overnight', 'if_airport', \n",
    "    'if_rain', 'if_snow', 'if_overcast', 'if_cloudy', 'if_clear', 'location_interaction_term'\n",
    "]\n",
    "\n",
    "# Transformer for continuous features which does a z-score normalization\n",
    "continuous_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Transformer for discrete features which does one-hot encoding\n",
    "discrete_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', continuous_transformer, continuous_features),\n",
    "    ('cat', discrete_transformer, discrete_features)\n",
    "])\n",
    "\n",
    "# Create & train random forest regressor\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(train_data_X, train_data_Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Use random forest regressor to predict & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict test_data\n",
    "train_prediction_Y = model.predict(train_data_X)\n",
    "test_prediction_Y = model.predict(test_data_X)\n",
    "\n",
    "# Calculate R^2 & MSE for train result\n",
    "train_r2 = r2_score(train_data_Y, train_prediction_Y)\n",
    "train_mse = mean_squared_error(train_data_Y, train_prediction_Y)\n",
    "\n",
    "# Calculate R^2 & MSE for test result\n",
    "test_r2 = r2_score(test_data_Y, test_prediction_Y)\n",
    "test_mse = mean_squared_error(test_data_Y, test_prediction_Y)\n",
    "\n",
    "# show the results\n",
    "print(f\"Train R^2: {train_r2:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print('\\n')\n",
    "print(f\"Test R^2: {test_r2:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stop spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
